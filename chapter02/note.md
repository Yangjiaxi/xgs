# Chapter 02 模型评估与选择

---

## 2.1 经验误差与过拟合

1. 训练误差/经验误差：学习器在训练集上的误差
2. 泛化误差：学习器在新样本上的误差
3. 显然，我们希望得到泛化误差小的学习器
4. 过拟合：学习器能力过强，把训练样本自身的一些特点当做潜在样本具有的一般性质，[难克服]
5. 欠拟合：学习器能力过弱，[易克服]

---

## 2.2 评估方法

- 为什么要划分数据集，为什么测试集不能与训练集相交？

  因为使用训练集中的样本来测试学习器，会得到过于乐观的结果。

  所以要对数据集$D$进行合理划分，得到训练集$S$和测试集$T$。

### 2.2.1 留出法

- 直接划分$D$，$D=S\cup T,S\cap T=\emptyset$
- 划分尽可能保持数据分布的一致性
- 留出法应当多次使用，$N$次实验后的平均作为评价结果
- 缺点：当数据集较小时无法准确反映学习器的性能
- [一般而言，测试集至少应含30个样例]

### 2.2.2 交叉验证法

- 将$D$划分为$k$个大小相似的[互斥]子集

  $D=D_{1}\cup D_{2}\cup ... \cup D_{k},\quad D_{i}\cap D_{j}=\emptyset(i\not=j)$

- 常用的$k$值是10 : 10折交叉验证

- 进行$k$次验证：

  - 使用除$D_{k}$外的$k-1$个子集进行训练
  - 使用$D_{k}$检验

- 划分方法可能造成误差，所以要使用$p$种划分方法 -> $p$次$k$折验证

- 总检验次数：$p*k$

- `EXTRA`:留一法(Leave-One-Out[LOO])

  - $|D|=m, k=m$，得到$m$个单元素子集
  - 优于训练集与样本原集仅相差一个元素，所以留一法的评估结果往往被认为比较准确
  - 当$m$较大时，时间开销难以忍受[主要缺点]

### 2.2.3 自助法

- 给定包含$m$个样本的数据集$D$
- 对D采样产生数据集$D'$
  - 从$D$中随机挑选一个元素，拷贝后放入$D'$
  - 重复动作$m$次
- $m$次操作后，必有元素多次出现，必有元素始终未出现
- 得到数据集$D'$，就是自助采样的结果
- 分析：
  - $m$个元素，每个元素每次被选到的概率是$\frac{1}{m}$，故不被选到的概率是$1-\frac{1}{m}$
  - 故$m$次抽取始终不被选到的概率是$(1-\frac{1}{m})^{m}$
  - 取极限${\lim_{m \to \infty}(1-\frac{1}{m})^{m}} \to \frac{1}{e} \approx 0.368 \approx \frac{1}{3}$
  - 我们有数据总量约$1/3$的、没在训练集中出现的样本能用于测试[包外估计]
- 在数据集较小、难以划分时，自助法很有用

### 2.2.4 调参与最终模型

- 很多强大的学习算法有不少参数需要设定
- 很多时候，参数调得好不好对最终模型性能有关键性影响
- 对于包含$m$个样本的数据集$D$，使用$S$训练，$T$测试。待模型选择完成后，应使用$D$整体重新训练模型，结果作为最终模型
- 称呼
  - 学得模型在实际使用中遇到的数据：测试数据
  - 用于评估与选择的数据集：验证集($T$集)

---

## 2.3 性能度量

为评估学习器$f$的性能，就要把学习器预测结果$f(x)$与真实标记$y$进行比较

- 对于离散数据集$D$，最常用的性能度量是“均方误差”
  $$
  E(f;D)=\frac{1}{m}{\sum_{i=1}^{m}(f(\boldsymbol{x}_{i})-y_{i})^2}
  $$




- 更一般的，对于数据服从分布$\mathcal{D}$和概率密度函数$p(\cdot)$，均方误差可描述为

$$
E(f;\mathcal{D})=\int_{\boldsymbol{x\sim \mathcal{D}}}(f(\boldsymbol{x})-y)^2p(\boldsymbol{x})d\boldsymbol{x}
$$

### 2.3.1 错误率与精度

- 对于离散的数据，样例集$D$分类的错误率定义为
  $$
  E(f;D)=\frac{1}{m}{\sum_{i=1}^{m}\mathbb{I}(f(\boldsymbol{x}_{i})\not= y_{i})}
  $$
  精度则定义为
  $$
  acc(f;D)=\frac{1}{m}{\sum_{i=1}^{m}\mathbb{I}(f(\boldsymbol{x}_{i})= y_{i})}\\
  = 1 - E(f;D)
  $$




- 更一般的，对于数据分布服从$\mathcal{D}$和概率密度函数$p(\cdot)$，错误率和精度可分别描述为
  $$
  E(f;\mathcal{D})=\int_{\boldsymbol{x\sim \mathcal{D}}}\mathbb{I}(f(\boldsymbol{x})\not= y)p(\boldsymbol{x})d\boldsymbol{x}
  \\
  acc(f;\mathcal{D})=\int_{\boldsymbol{x\sim \mathcal{D}}}\mathbb{I}(f(\boldsymbol{x})= y)p(\boldsymbol{x})d\boldsymbol{x}\\
  =1-E(f;\mathcal{D})
  $$


### 2.3.2 查准率、查全率与$F1$

- 假设有一车西瓜，里面有好瓜和坏瓜，现在需要挑选出好瓜来

- 真正例($TP$):挑选出的好瓜

  假正例($FP$):挑选出的坏瓜

  假反例($FN$):未被挑选出的好瓜

  真反例($TN$):未被挑选出的坏瓜

- 查准率($P$,precision)
  $$
  P=\frac{TP}{TP+FP}
  $$
  含义：挑出的西瓜中有多少是好瓜

- 查全率($R$,recall)
  $$
  R=\frac{TP}{TP+FN}
  $$
  含义：有多少好瓜被挑了出来

- 查全率和查准率是一对相互矛盾的量

  - 要想查准率高，只挑选最有把握的瓜即可，那么会有很多好瓜不会被挑出来
  - 要想查全率高，尽可能的多挑选即可，那么就会有很多坏瓜被挑出来
  - [通常只有在一些简单的任务中，$P$和$R$才有可能都很高]

- $PR$曲线

  - $PR$曲线反映了$P$与$R$之间的函数关系
  - $PR$曲线直观的显示出学习器在某个样本上的性能，若学习器$\mathfrak{L_{a}}$的$PR$曲线被$\mathfrak{L_{b}}$完全包围，则说后者的性能[在这个样本上的表现]优于前者
  - 若两条$PR$曲线相交，一般可以比较线下面积，然而过于繁琐
  - 人们设计了其他的性能度量，同时考虑了$P$与$R$

- 平衡点(Break-Even Point[BEP])

  直线$P=R$与$PR$曲线的交点，$BEP$较大的学习器性能好

  - \[过于简化\](缺点)

- $F1$度量
  $$
  F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}
  $$
  然而，在某些情况下，对查全率与查准率的青睐程度是不同的，比如:

  - 商品推荐中为了不打扰用户，查准率很重要
  - 逃犯信息检索中，要尽可能少漏掉逃犯，查全率很重要

  所以，$F1$度量的一般形式$F_{\beta}$，允许我们表达对查全率和查准率的不同偏好
  $$
  F_{\beta}=\frac{(1+\beta^{2})\times P \times R}{(\beta^2\times P)+R}
  $$

  - 其中$\beta>0$，反映了查全率对查准率的相对重要性，也就是
    $$
    \beta=\frac{查全率的重要性}{查准率的重要性}
    $$

    - 显然$F1$度量认为两者同样重要
    - $\beta>1$时查全率有更大影响
    - $\beta<1$时查准率有更大影响

  - 事实上，$F$度量是一种调和平均

### 2.3.3 ROC与AUC

- 曲线见图片[ROC&AUC.png]

- ROC曲线(Receiver Operating Characteristic Curve)[受试者工作特征曲线]

  - ROC首先把所有样本按照预测结果从大到小排序

  - 每次步进1，把这个样例的预测值$k_{i}$作为阈值，计算TPR与FPR

    - $$
      TPR=\frac{TP}{TP+FN}\\
      FPR=\frac{FP}{FP+TN}
      $$

  - 具体如下：

    - 考虑$k_{0}>\forall k_{i}$，有$TP=FP=0$，也就是所有样本都判断为假，此时$TPR=FPR=0$，曲线经过点(0,0)

    - 考虑$k_{last}<\forall k_{i}$，有$FN=TN=0$，也就是所有样本都被判断为真，此时$TPR=FPR=1$，曲线经过点(1,1)

    - 对于一个样例集，正例个数为$m^+$，反例个数为$m^-$。对于任一样例点的$k_{\alpha}$，假设它的前一个样例坐标为$(x,y)$，若这个样例为真正例，它的坐标为$(x,y+\frac{1}{m^+})$；若这个样例为假正例，它的坐标就为$(x+\frac{1}{m^-},y)$

      证明：

      对于前一个点有
      $$
      x=FPR=\frac{FP}{FP+TN}\\
      y=TPR=\frac{TP}{TP+FN}
      $$
      则，对于当前点，若为真正例
      $$
      y'=\frac{TP'}{TP'+FN'}=\frac{TP+1}{(TP+1)+(FN-1)}\\=\frac{TP+1}{TP+FN}
      =\frac{TP}{TP+FN}+\frac{1}{TP+FN}\\=y+\frac{1}{m^+}
      $$
      而$x$坐标的值不变，所以新的坐标为$(x,y+\frac{1}{m^+})$

      同理可证假正例情况。

  - 当所有样例都被完美的处理，即没有出现任何negative的情况，$FP=FN=0$，此时$TPR=1, FPR=0$，为最佳情况。

  - 我们可以看出，ROC线下面积反映了性能优劣，这个指标被称为AUC(Area Under ROC Curve)

### 2.3.4 代价敏感错误率与代价曲线

~~没看懂，以后再回头看~~

---

## 2.4 比较检验

